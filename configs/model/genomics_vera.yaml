# @package fixed

trainer_config:
  max_steps: 100_000
  max_epochs: 100_000
  limit_val_batches: 1000
  val_check_interval: 10_000
  limit_test_batches: 10_000

batch_size: 256

checkpoint_config:
  save_last: True

earlystop_config:

ood_dataset: ${fixed.dataset}

model_name: VERA
model_config:
  arch_name: seq_classifier
  arch_config:
    in_channels: ${fixed.num_cat}
    num_filters: 128
    fc_hidden_size: 1000
    num_classes: 1
    kernel_size: 20

  learning_rate: 0.00003
  beta1: 0.0
  beta2: 0.9
  weight_decay: 0.0
  n_classes: 1
  uncond: False
  gen_learning_rate: 0.00006
  ebm_iters: 1
  generator_iters: 1
  entropy_weight: 0.0001

  generator_type: vera_discrete
  generator_arch_name: seq_generator
  generator_config:
    noise_dim: 128
    post_lr: 0.00003
    init_post_logsigma: 0.1
  generator_arch_config:
    inp_dim: ${fixed.model_config.generator_config.noise_dim}
    num_classes: ${fixed.num_cat}
    seq_length: ${fixed.data_shape.0}

  min_sigma: 0.01
  max_sigma: 0.3
  p_control: 0.0
  n_control: 0.0
  pg_control: 0.1
  clf_ent_weight: 0.0
  ebm_type: p_x
  clf_weight: 0.0
  warmup_steps: 2500
  no_g_batch_norm: False
  batch_size: ${fixed.batch_size}
  lr_decay: 0.3
  lr_decay_epochs: [150, 180]
